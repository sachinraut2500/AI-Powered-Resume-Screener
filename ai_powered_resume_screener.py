# -*- coding: utf-8 -*-
"""AI-Powered Resume Screener

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o3OR4VeCzokBLLmhDBl_dThg6i_3XQrR
"""

"""
AI-Powered Resume Screener
--------------------------
Ranks resumes against a job description using TF-IDF cosine similarity + skill overlap.
Supports PDF, DOCX, and TXT resumes.
"""

import re
import argparse
from pathlib import Path
from typing import Dict, Set, Tuple, List, Optional

import fitz  # PyMuPDF for PDF parsing
from docx import Document
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# -----------------------------
# Helpers for File Parsing
# -----------------------------

def extract_text_from_pdf(path: Path) -> str:
    """Extract text from a PDF file."""
    text_chunks = []
    with fitz.open(path) as doc:
        for page in doc:
            text_chunks.append(page.get_text("text"))
    return "\n".join(text_chunks)


def extract_text_from_docx(path: Path) -> str:
    """Extract text from a DOCX file."""
    doc = Document(path)
    paragraphs = [p.text for p in doc.paragraphs]
    return "\n".join(paragraphs)


def normalize_text(s: str) -> str:
    """Lowercase + collapse whitespace + strip nulls."""
    return " ".join(s.lower().replace("\x00", " ").split())


def load_job_description(path: Path) -> str:
    return normalize_text(path.read_text(encoding="utf-8", errors="ignore"))


def load_resumes_texts(folder: Path) -> Dict[str, str]:
    """Load multiple resumes (PDF/DOCX/TXT) into {filename: text} dict."""
    texts: Dict[str, str] = {}
    for p in folder.rglob("*"):
        if not p.is_file():
            continue
        try:
            if p.suffix.lower() == ".pdf":
                txt = extract_text_from_pdf(p)
            elif p.suffix.lower() == ".docx":
                txt = extract_text_from_docx(p)
            elif p.suffix.lower() == ".txt":
                txt = p.read_text(encoding="utf-8", errors="ignore")
            else:
                continue
            texts[p.name] = normalize_text(txt)
        except Exception as e:
            print(f"[WARN] Could not parse {p.name}: {e}")
    return texts


# -----------------------------
# NLP Utilities
# -----------------------------

EMAIL_RE = re.compile(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+")
PHONE_RE = re.compile(r"(\+?\d[\d\-\s()]{7,}\d)")


def extract_contacts(text: str) -> Tuple[Optional[str], Optional[str]]:
    """Extract first email & phone found in text."""
    email_match = EMAIL_RE.search(text)
    phone_match = PHONE_RE.search(text)
    email = email_match.group(0) if email_match else None
    phone = phone_match.group(0) if phone_match else None
    return email, phone


def load_skills(path: Path) -> Set[str]:
    """Load skills vocabulary (one per line)."""
    skills = set()
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            token = line.strip().lower()
            if token:
                skills.add(token)
    return skills


def extract_skills_from_text(text: str, skills_db: Set[str]) -> Set[str]:
    """Naive skill extractor: check if skills from DB appear in text."""
    tokens = [t for t in re.split(r"[^a-z0-9\+#\.]", text.lower()) if t]
    stream = " ".join(tokens)
    found = set()
    for skill in skills_db:
        pattern = r"(?:^|\s)" + re.escape(skill.replace("/", " ")) + r"(?:\s|$)"
        if re.search(pattern, stream):
            found.add(skill)
    return found


# -----------------------------
# Matching & Ranking
# -----------------------------

def jaccard(a: Set[str], b: Set[str]) -> float:
    if not a and not b:
        return 0.0
    inter = len(a & b)
    union = len(a | b)
    return inter / union if union else 0.0


def rank_resumes(resumes: List[Dict], job_text: str, jd_skills: Set[str],
                 w_cos: float, w_skill: float) -> List[Dict]:
    """Rank resumes using cosine similarity + skill overlap."""
    corpus = [job_text] + [r["text"] for r in resumes]
    vectorizer = TfidfVectorizer(stop_words="english", ngram_range=(1, 2))
    X = vectorizer.fit_transform(corpus)
    job_vec = X[0]
    res_vecs = X[1:]
    cosines = cosine_similarity(res_vecs, job_vec)

    ranked = []
    for i, r in enumerate(resumes):
        cos = float(cosines[i][0])
        skill_overlap = jaccard(r["skills"], jd_skills)
        score = w_cos * cos + w_skill * skill_overlap
        ranked.append({
            "filename": r["filename"],
            "score": score,
            "cosine_similarity": cos,
            "skill_overlap": skill_overlap,
            "skills_matched": r["skills"] & jd_skills,
            "email": r.get("email"),
            "phone": r.get("phone"),
        })

    ranked.sort(key=lambda x: x["score"], reverse=True)
    return ranked


# -----------------------------
# Main CLI
# -----------------------------

def parse_args():
    p = argparse.ArgumentParser(description="AI-Powered Resume Screener")
    p.add_argument("--resumes", required=True, type=str, help="Folder with resumes (pdf/docx/txt)")
    p.add_argument("--job", required=True, type=str, help="Path to job description (txt)")
    p.add_argument("--skills", default="skills.txt", type=str, help="Skills vocabulary file")
    p.add_argument("--out", default="ranked_resumes.csv", type=str, help="Output CSV path")
    p.add_argument("--w_cos", default=0.7, type=float, help="Weight for cosine similarity")
    p.add_argument("--w_skill", default=0.3, type=float, help="Weight for skill overlap")
    return p.parse_args()


def main():
    args = parse_args()
    resumes_dir = Path(args.resumes)
    job_path = Path(args.job)
    skills_path = Path(args.skills)

    job_text = load_job_description(job_path)
    resumes_texts = load_resumes_texts(resumes_dir)
    skills_db = load_skills(skills_path)
    jd_skills = extract_skills_from_text(job_text, skills_db)

    resumes = []
    for fname, text in resumes_texts.items():
        email, phone = extract_contacts(text)
        res_skills = extract_skills_from_text(text, skills_db)
        resumes.append({
            "filename": fname,
            "text": text,
            "skills": res_skills,
            "email": email,
            "phone": phone
        })

    ranked = rank_resumes(resumes, job_text, jd_skills, args.w_cos, args.w_skill)

    # Save to CSV
    rows = []
    for r in ranked:
        rows.append({
            "filename": r["filename"],
            "score": round(r["score"], 4),
            "cosine_similarity": round(r["cosine_similarity"], 4),
            "skill_overlap": round(r["skill_overlap"], 4),
            "num_skills_matched": len(r["skills_matched"]),
            "skills_matched": ", ".join(sorted(r["skills_matched"])),
            "email": r.get("email") or "",
            "phone": r.get("phone") or ""
        })
    df = pd.DataFrame(rows)
    df.to_csv(args.out, index=False)

    print(f"âœ… Wrote {args.out}")
    print(df.to_string(index=False))


if __name__ == "__main__":
    main()